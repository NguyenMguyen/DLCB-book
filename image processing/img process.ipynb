{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# print(cv2.__version__)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('img resize.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show anh mau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = int(img.shape[1]/5)\n",
    "# h = int(img.shape[0]/5)\n",
    "# dim = (w, h)\n",
    "  \n",
    "# # resize image\n",
    "# img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "# print('Resized Dimensions : ',img.shape)\n",
    "\n",
    "cv2.imshow(\"Resized image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert to gray and show img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = img[:,:,0]\n",
    "g = img[:,:,1]\n",
    "b = img[:,:,2]\n",
    "\n",
    "gray = (0.299*r + 0.587*g + 0.114*b).astype(np.uint8)\n",
    "\n",
    "cv2.imshow('gray', gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('gray', img_gray)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Dimensions :  (400, 228, 3)\n"
     ]
    }
   ],
   "source": [
    "w = int(img.shape[1]/2)\n",
    "h = int(img.shape[0]/2)\n",
    "dim = (w, h)\n",
    "\n",
    "# resize image\n",
    "img_resize = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "print('Resized Dimensions : ',img_resize.shape)\n",
    "\n",
    "cv2.imshow(\"Resized image\", img_resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate = np\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "rotate = gray[:,::-1]\n",
    "rotate = rotate.T\n",
    "# rotate = img[::-1,:]\n",
    "# rotate = img[:,:,::-1]\n",
    "cv2.imshow(\"rotate\", rotate)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate = gray[::-1,:]\n",
    "rotate = rotate.T\n",
    "cv2.imshow(\"rotate\", rotate)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate = img[::-1,:]\n",
    "cv2.imshow(\"rotate\", rotate)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "rotate = img[:,::-1]\n",
    "cv2.imshow(\"rotate\", rotate)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rows, cols) = img.shape[:2]\n",
    "\n",
    "# getRotationMatrix2D creates a matrix needed for transformation.\n",
    "# We want matrix for rotation w.r.t center to 45 degree without scaling.\n",
    "M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 60, 1)\n",
    "res = cv2.warpAffine(img, M, (cols, rows))\n",
    "cv2.imshow(\"rotate\", res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = np.copy(img_gray)\n",
    "threshold = 180\n",
    "thresh[thresh>threshold] = 255\n",
    "thresh[thresh<=threshold] = 0\n",
    "cv2.imshow(\"thresh\", thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh1 = cv2.threshold(img_gray, 120, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(img_gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(img_gray, 120, 255, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold(img_gray, 120, 255, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold(img_gray, 120, 255, cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow('Binary Threshold', thresh1)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Binary Threshold Inverted', thresh2)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Truncated Threshold', thresh3)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Set to 0', thresh4)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Set to 0 Inverted', thresh5)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line, circle detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(img_gray, 100, 200)\n",
    "\n",
    "cv2.imshow('canny', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply HoughLinesP method to\n",
    "# to directly obtain line end points\n",
    "lines_list =[]\n",
    "lines = cv2.HoughLinesP(\n",
    "            edges, # Input edge image\n",
    "            1, # Distance resolution in pixels\n",
    "            np.pi/180, # Angle resolution in radians\n",
    "            threshold=100, # Min number of votes for valid line\n",
    "            minLineLength=5, # Min allowed length of line\n",
    "            maxLineGap=10 # Max allowed gap between line for joining them\n",
    "            )\n",
    "\n",
    "img_line = np.copy(img)\n",
    "# Iterate over points\n",
    "for points in lines:\n",
    "      # Extracted points nested in the list\n",
    "    x1,y1,x2,y2=points[0]\n",
    "    # Draw the lines joing the points\n",
    "    # On the original image\n",
    "    cv2.line(img_line,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "    # Maintain a simples lookup list for points\n",
    "    lines_list.append([(x1,y1),(x2,y2)])\n",
    "    \n",
    "cv2.imshow('line', img_line)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blur using 3 * 3 kernel.\n",
    "gray_blurred = cv2.blur(img_gray, (3, 3))\n",
    "\n",
    "# Apply Hough transform on the blurred image.\n",
    "detected_circles = cv2.HoughCircles(gray_blurred,\n",
    "                                    cv2.HOUGH_GRADIENT, 1, 20, param1=50,\n",
    "                                    param2=30, minRadius=1, maxRadius=40)\n",
    "\n",
    "img_circle = np.copy(img)\n",
    "# Draw circles that are detected.\n",
    "if detected_circles is not None:\n",
    "\n",
    "    # Convert the circle parameters a, b and r to integers.\n",
    "    detected_circles = np.uint16(np.around(detected_circles))\n",
    "\n",
    "    for pt in detected_circles[0, :]:\n",
    "        a, b, r = pt[0], pt[1], pt[2]\n",
    "\n",
    "        # Draw the circumference of the circle.\n",
    "        cv2.circle(img_circle, (a, b), r, (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a small circle (of radius 1) to show the center.\n",
    "        cv2.circle(img_circle, (a, b), 1, (0, 0, 255), 3)\n",
    "        cv2.imshow(\"Detected Circle\", img_circle)\n",
    "        cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply identity kernel\n",
    "# In an Identity Kernel matrix the value of the middle element is 1\n",
    "# The values of all the other elements are 0\n",
    "id_kernel = np.array([[0, 0, 0],\n",
    "                    [0, 1, 0],\n",
    "                    [0, 0, 0]])\n",
    "  \n",
    "# Filtered image is obtained using the variable flt_img\n",
    "# cv2.fliter2D() is the function used\n",
    "# src is the source of image(here, img)\n",
    "# ddepth is destination depth. -1 will mean output image will have same depth as input image\n",
    "# kernel is used for specifying the kernel operation (here, id_kernel)\n",
    "flt_img = cv2.filter2D(src=img, ddepth=-1, kernel=id_kernel)\n",
    "  \n",
    "# Display the filtered image using cv2.imshow() function\n",
    "# Here, output image is same as input image since we are using identity kernel\n",
    "cv2.imshow('Identity', flt_img)\n",
    "\n",
    "# cv2.waitkey(delay) function holds the screen till any key is pressed by the user\n",
    "# It pauses the screen for delay milliseconds if the delay is a positive value\n",
    "# It pauses the screen for a key event infinitely if the delay is 0 or negative\n",
    "cv2.waitKey(0)\n",
    "  \n",
    "# cv2.destroyAllWindows() function deletes all the GUI windows from memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "box blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel for box blur filter\n",
    "# It is a unity matrix which is divided by 9\n",
    "box_blur_ker = np.array([[0.1111111, 0.1111111, 0.1111111],\n",
    "                         [0.1111111, 0.1111111, 0.1111111],\n",
    "                         [0.1111111, 0.1111111, 0.1111111]])\n",
    "\n",
    "# Applying Box Blur effect\n",
    "# Using the cv2.filter2D() function\n",
    "# src is the source of image(here, img)\n",
    "# ddepth is destination depth. -1 will mean output image will have same depth as input image\n",
    "# kernel is used for specifying the kernel operation (here, box_blur_ker)\n",
    "Box_blur = cv2.filter2D(src=img, ddepth=-1, kernel=box_blur_ker)\n",
    "cv2.imshow('blur', Box_blur)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sharpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply kernel for sharpening\n",
    "sharp_kernel = np.array([[0, -1, 0],\n",
    "                         [-1, 5, -1],\n",
    "                         [0, -1, 0]])\n",
    "\n",
    "# Sharpeneded image is obtained using the variable sharp_img\n",
    "# cv2.fliter2D() is the function used\n",
    "# src is the source of image(here, img)\n",
    "# ddepth is destination depth. -1 will mean output image will have same depth as input image\n",
    "# kernel is used for specifying the kernel operation (here, sharp_kernel)\n",
    "sharp_img = cv2.filter2D(src=img, ddepth=-1, kernel=sharp_kernel)\n",
    "cv2.imshow('sharpen', sharp_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = np.array([[0, 1, 0],\n",
    "               [1, -4, 1],\n",
    "               [0, 1, 0]])\n",
    "e2 = np.array([[1, 0, -1],\n",
    "               [0, 0, 0],\n",
    "               [-1, 0, 1]])\n",
    "e3 = np.array([[-1, -1, -1],\n",
    "               [-1, 8, -1],\n",
    "               [-1, -1, -1]])\n",
    "edge_kernel = [e1, e2, e3]\n",
    "for e in edge_kernel:\n",
    "    edge = cv2.filter2D(src=img, ddepth=-1, kernel=e)\n",
    "    cv2.imshow('edge', edge)\n",
    "    cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(img, kernel, p=1, s=1):\n",
    "    (m, n) = img.shape\n",
    "    k = kernel.shape[0]\n",
    "    pad_k = int((k-1)/2)\n",
    "    m_Y = int((m-k+2*p)/s + 1)\n",
    "    n_Y = int((n-k+2*p)/s + 1)\n",
    "    # print(m_Y, n_Y)\n",
    "\n",
    "    Y = np.zeros((m_Y, n_Y))\n",
    "    pad_m = np.zeros((m, p))\n",
    "    X = np.concatenate((pad_m, img, pad_m), axis=1)\n",
    "    pad_n = np.zeros((p, X.shape[1]))\n",
    "    X = np.concatenate((pad_n, X, pad_n), axis=0)\n",
    "\n",
    "    i = j = 0\n",
    "    c1 = c2 = 0\n",
    "    while(c1+pad_k+2 <= m+2*p):\n",
    "        \n",
    "        while(c2+pad_k+2 <= n+2*p):\n",
    "            A = X[c1-pad_k+1:c1+pad_k+2, c2-pad_k+1:c2+pad_k+2]\n",
    "            Y[i, j] = np.sum((A*kernel))\n",
    "            j += 1\n",
    "            # print(c1+1, c2+1)\n",
    "            c2 += s\n",
    "\n",
    "        c2=0\n",
    "        j=0\n",
    "        c1 += s\n",
    "        i += 1\n",
    "\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0.]\n",
      " [0. 9. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 1, 1],\n",
    "              [1, 1, 1],\n",
    "              [1, 1, 1]])\n",
    "blur_kernel = np.array([[1, 1, 1],\n",
    "                        [1, 1, 1],\n",
    "                        [1, 1, 1]])\n",
    "# kernel = np.copy(X)\n",
    "(X_res, Y) = convolution(X, blur_kernel,3,3)\n",
    "print(X_res)\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = np.array([[0, 1, 0],\n",
    "               [1, -4, 1],\n",
    "               [0, 1, 0]])\n",
    "e2 = np.array([[1, 0, -1],\n",
    "               [0, 0, 0],\n",
    "               [-1, 0, 1]])\n",
    "e3 = np.array([[-1, -1, -1],\n",
    "               [-1, 8, -1],\n",
    "               [-1, -1, -1]])\n",
    "edge_kernel = [e1, e2, e3]\n",
    "for e in edge_kernel:\n",
    "    (X_res, Y) = convolution(img_gray, e)\n",
    "    cv2.imshow('sharp', Y)\n",
    "    cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31671a60cee805c34c73116577b485118ff3a75c458d3004d49632c19702ac60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
